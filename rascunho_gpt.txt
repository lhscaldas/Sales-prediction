Um desafio de mineração de dados consiste em treinar um algoritmo de aprendizado de máquina para prever vendas de produtos. Para isso, foram fornecidos diversos dados no formato csv. Segue abaixo as 10 primeiras linhas de cada csv disponível.

train.csv
id,date,store_nbr,family,sales,onpromotion
0,2013-01-01,1,AUTOMOTIVE,0.0,0
1,2013-01-01,1,BABY CARE,0.0,0
2,2013-01-01,1,BEAUTY,0.0,0
3,2013-01-01,1,BEVERAGES,0.0,0
4,2013-01-01,1,BOOKS,0.0,0
5,2013-01-01,1,BREAD/BAKERY,0.0,0
6,2013-01-01,1,CELEBRATION,0.0,0
7,2013-01-01,1,CLEANING,0.0,0
8,2013-01-01,1,DAIRY,0.0,0
9,2013-01-01,1,DELI,0.0,0
10,2013-01-01,1,EGGS,0.0,0

test.csv
id,date,store_nbr,family,onpromotion
3000888,2017-08-16,1,AUTOMOTIVE,0
3000889,2017-08-16,1,BABY CARE,0
3000890,2017-08-16,1,BEAUTY,2
3000891,2017-08-16,1,BEVERAGES,20
3000892,2017-08-16,1,BOOKS,0
3000893,2017-08-16,1,BREAD/BAKERY,12
3000894,2017-08-16,1,CELEBRATION,0
3000895,2017-08-16,1,CLEANING,25
3000896,2017-08-16,1,DAIRY,45
3000897,2017-08-16,1,DELI,18

holidays_events.csv
date,type,locale,locale_name,description,transferred
2012-03-02,Holiday,Local,Manta,Fundacion de Manta,False
2012-04-01,Holiday,Regional,Cotopaxi,Provincializacion de Cotopaxi,False
2012-04-12,Holiday,Local,Cuenca,Fundacion de Cuenca,False
2012-04-14,Holiday,Local,Libertad,Cantonizacion de Libertad,False
2012-04-21,Holiday,Local,Riobamba,Cantonizacion de Riobamba,False
2012-05-12,Holiday,Local,Puyo,Cantonizacion del Puyo,False
2012-06-23,Holiday,Local,Guaranda,Cantonizacion de Guaranda,False
2012-06-25,Holiday,Regional,Imbabura,Provincializacion de Imbabura,False

oil.csv
date,dcoilwtico
2013-01-01,
2013-01-02,93.14
2013-01-03,92.97
2013-01-04,93.12
2013-01-07,93.2
2013-01-08,93.21
2013-01-09,93.08
2013-01-10,93.81
2013-01-11,93.6
2013-01-14,94.27

transactions.csv
date,store_nbr,transactions
2013-01-01,25,770
2013-01-02,1,2111
2013-01-02,2,2358
2013-01-02,3,3487
2013-01-02,4,1922
2013-01-02,5,1903
2013-01-02,6,2143
2013-01-02,7,1874
2013-01-02,8,3250
2013-01-02,9,2940

sample_submission.csv
id,sales
3000888,0.0
3000889,0.0
3000890,0.0
3000891,0.0
3000892,0.0
3000893,0.0
3000894,0.0
3000895,0.0
3000896,0.0
3000897,0.0

o algoritmo deve ser treinado usando o train.csv (usando o holiday_events.csv, oil.csv e transactions.csv para gerar features extras) e depois fazer as previsões para o test.csv (usando o holiday_events.csv, oil.csv e transactions.csv). O resuldo das previsões deve estar no formato previsto pelo sample_submission.csv.

Escreva um código em python que consiga realizar essa tarefa.

As duas classes abaixo foram criadas para pre-processar os dados e depois fazer as previsões. Avalie elas e encontre possíveis fontes de erro e melhoreias que podem ser feitas.

class Preprocessor():
    def __init__(self):
        self.train = pd.read_csv('train.csv')
        self.test = pd.read_csv('test.csv')
        self.holiday = pd.read_csv('holidays_events.csv')
        self.sample = pd.read_csv('sample_submission.csv')
        self.oil = pd.read_csv('oil.csv')
        self.stores = pd.read_csv('stores.csv')
        self.transactions = pd.read_csv('transactions.csv')

    def gen_series(self):
        df = self.train.copy()
        df['item'] = "S" + df['store_nbr'].astype(str) + "_" + df['family'].astype(str)
        self.series = df.pivot(index='date', columns='item', values='sales')

    def preprocess_traintest(self, df):
        df['date'] = df['date'].map(lambda x: date.fromisoformat(x))
        df['weekday'] = df['date'].map(lambda x: x.weekday())
        df['year'] = df['date'].map(lambda x: x.year)
        df['month'] = df['date'].map(lambda x: x.month)
        df['day'] = df['date'].map(lambda x: x.day)
        df['eomd'] = df['date'].map(lambda x: calendar.monthrange(x.year, x.month)[1])
        df['payday'] = ((df['day'] == df['eomd'])|(df['day'] == 15)).astype(int)
        df.drop(['id', 'eomd'], axis=1, inplace=True)
        return df
    
    def preprocess_oil(self):
        oil = self.oil.copy()
        oil['month'] = oil['date'].map(lambda x: int(x.replace('-', '')[:6]))
        oil['month_avg'] = oil.groupby('month')['dcoilwtico'].transform('mean')
        oil['tmp'] = oil['dcoilwtico'].map(np.isnan)
        oil['month_avg'] = oil['tmp'] * oil['month_avg']
        oil['dcoilwtico'].fillna(0, inplace=True)
        oil['dcoilwtico'] = oil['dcoilwtico'] + oil['month_avg']
        oil['dcoilwtico'] = oil['dcoilwtico'].astype(float)
        oil = oil.drop(['month', 'month_avg', 'tmp'], axis=1)
        oil['date'] = oil['date'].map(lambda x: date.fromisoformat(x))
        self.oil = oil

    def preprocess_holiday(self):
        # separar holiday de event e earthquake
        holiday = self.holiday.copy()
        holiday['date'] = holiday['date'].map(lambda x: date.fromisoformat(x))
        holiday = holiday[(holiday['transferred']==False)&(holiday['type']!='Work Day')]
        event = holiday[holiday['type']=='Event']
        earthquake = event[event['description'].str.startswith('Terremoto Manabi')]
        event = event[event['description'].str.startswith('Terremoto Manabi')==False]
        # arrumar os dados de event e earthquake
        event = event[['date', 'description']]
        event.rename({'description': 'event_name'}, axis=1, inplace=True)
        earthquake = earthquake[['date', 'description']]
        earthquake.rename({'description': 'earthquake'}, axis=1, inplace=True)
        # separar os tipos de feriado
        h_local = holiday[holiday['locale']=='Local']
        h_local = h_local[['date', 'locale_name', 'description']]
        h_local = h_local.rename({'locale_name': 'city', 'description': 'local_holiday_name'}, axis=1)
        h_regional = holiday[holiday['locale']=='Regional']
        h_regional = h_regional[['date', 'locale_name', 'description']]
        h_regional = h_regional.rename({'locale_name': 'state', 'description': 'regional_holiday_name'}, axis=1)
        h_national = holiday[holiday['locale']=='National']
        h_national = h_national[['date', 'description']]
        h_national = h_national.rename({'description': 'national_holiday_name'}, axis=1)
        return event, earthquake, h_local, h_regional, h_national
    
    def merge_tables(self, df):
        event, earthquake, h_local, h_regional, h_national = self.preprocess_holiday()
        df = df.merge(self.oil, on='date', how='left')
        df = df.merge(self.stores, on='store_nbr', how='left')
        df = df.merge(event, on='date', how='left').fillna('0')
        df = df.merge(earthquake, on='date', how='left').fillna('0')
        df = df.merge(h_local, on=['date', 'city'], how='left').fillna('0')
        df = df.merge(h_regional, on=['date', 'state'], how='left').fillna('0')
        df = df.merge(h_national, on='date', how='left').fillna('0')
        df = df.merge(self.transactions, on=['date', 'store_nbr'], how='left').fillna(0)

        df['dcoilwtico'] = df['dcoilwtico'].astype(float)
        return df
    
    def label_encoding(self):
        cat_features = ['family', 'store_nbr', 'city', 'state', 'type', 'cluster',
                'event_name', 'earthquake', 'local_holiday_name', 'regional_holiday_name', 'national_holiday_name']
        for col in cat_features:
            try:
                le = LabelEncoder()
                self.train[col] = le.fit_transform(self.train[col])
                self.test[col] = le.transform(self.test[col])
            except Exception as e:
                # Trata qualquer exceção que ocorrer
                print(f"Erro ao processar a coluna '{col}': {e}")

    def date_cut2017(self, df):
        split_date = "2017-01-01"
        split_datetime = datetime.strptime(split_date, "%Y-%m-%d")
        if 'date' in df.columns.tolist():       
            df = df[df['date']>=split_datetime.date()]
        else:
            df = df.loc[split_date:]
        return df

    def generate_dataset(self):
        self.gen_series()
        self.train = self.preprocess_traintest(self.train)
        self.test = self.preprocess_traintest(self.test)
        self.preprocess_oil()
        self.train = self.merge_tables(self.train)
        self.test = self.merge_tables(self.test)
        self.label_encoding()
        self.series = self.date_cut2017(self.series)
        self.train = self.date_cut2017(self.train)

    def fourier(self):
        y = self.series.copy()
        y.index = pd.to_datetime(y.index)
        y.index = y.index.to_period('D')
        fourier = CalendarFourier(freq='M', order=4)
        dp = DeterministicProcess(
            index=y.index,
            constant=True,
            order=1,
            seasonal=True,
            additional_terms=[fourier],
            drop=True,
        )
        return dp
    
    def date_split(self, df, split_date):
        split_datetime = datetime.strptime(split_date, "%Y-%m-%d")
        split_datetime2 = split_datetime + timedelta(days=1)
        split_date2 = split_datetime2.strftime("%Y-%m-%d")
        if 'date' in df.columns.tolist():     
            df_train = df[df['date']<=split_datetime.date()]
            df_valid = df[df['date']>=split_datetime2.date()]
        else:
            df_train, df_valid = df.loc[:split_date], df.loc[split_date2:]
        return df_train, df_valid

    def generate_training_data(self):
        y = self.series.copy()
        # X1: Features for Linear Regression
        dp = self.fourier()
        X1 = dp.in_sample()
        # X2: Features for XGBoost
        X2 = self.train.drop(['sales','store_nbr','family','year'], axis=1)
        return  y, X1, X2
    
    def generate_test_data(self):
        # X1: Features for Linear Regression
        dp = self.fourier()
        X1 = dp.out_of_sample(steps=16)
        # X2: Features for XGBoost
        X2 = self.test.drop(['store_nbr','family','year'], axis=1)
        return  X1, X2


class BoostedHybrid:
    def __init__(self, model_1=Ridge(), model_2=XGBRegressor()):
        self.model_1 = model_1
        self.model_2 = model_2
        self.y_columns = None
        self.y_fit = None
        self.y_resid = None

    def fit(self, X_1, X_2, y):
        self.model_1.fit(X_1, y)

        y_fit = pd.DataFrame(
            self.model_1.predict(X_1), 
            index=X_1.index, columns=y.columns,
        )
        y_resid = y.subtract(y_fit, axis='columns', fill_value=0)
        y_resid = y_resid.stack().squeeze()
        X_2 = X_2.drop(['date'], axis=1)
        self.model_2.fit(X_2, y_resid.values)
        self.y_columns = y.columns
        self.y_fit = y_fit
        self.y_resid = y_resid

    def predict(self, X_1, X_2):
        y_pred = pd.DataFrame(
            self.model_1.predict(X_1),
            index=X_1.index, columns=self.y_columns,
        )
        y_pred = y_pred.stack().squeeze()
        X_2 = X_2.drop(['date'], axis=1)
        y_pred += self.model_2.predict(X_2)
        return y_pred.unstack()
    
    def validation_results(self, y_train, y_valid, y_fit, y_pred, verbose=True, plot=True):
            y_fit = y_fit.clip(0.0)
            y_pred = y_pred.clip(0.0)
            error_train = np.sqrt(mean_squared_log_error(y_train, y_fit))
            error_valid = np.sqrt(mean_squared_log_error(y_valid, y_pred))
            if verbose:
                print(f"erro de treinamento: {error_train}")
                print(f"erro de validação: {error_valid}")
            if plot:
                y = pd.concat([y_train, y_valid], axis=0)
                families = y.columns[0:6]
                axs = y.loc(axis=1)[families].plot(
                    subplots=True, figsize=(11, 9), marker='.', linestyle='-',
                    color='0.25', label='vendas', linewidth=1, markersize=4, alpha=0.5)
                _ = y_fit.loc(axis=1)[families].plot(subplots=True, color='C0', ax=axs)
                _ = y_pred.loc(axis=1)[families].plot(subplots=True, color='C3', ax=axs)
                for ax, family in zip(axs, families):
                    ax.legend([])
                    ax.set_ylabel(family)
                plt.show()
            return error_train, error_valid
    
    def generate_csv(self, y_test):
        y_test = y_test.reset_index(drop=False)
        y_test = y_test.rename(columns={'index': 'date'})
        y_test['date'] = y_test['date'].astype(str)
        unpivoted = (y_test
                        .melt(id_vars='date', var_name='item', value_name='sales')
                        )
        unpivoted[['store_nbr', 'family']] = unpivoted['item'].str.extract(r'S(\d+)_(.+)')
        unpivoted = (unpivoted
            .dropna()
            .drop(['item'], axis=1)
        )
        output = pd.read_csv(
                    'test.csv',
                    usecols=['id','store_nbr', 'family', 'date', 'onpromotion'],
                    dtype={
                        'store_nbr': 'category',
                        'family': 'category',
                        'onpromotion': 'uint32',
                    },
                    parse_dates=['date'],
                )
        output['date'] = output['date'].astype(str)
        output = output.merge(unpivoted, on=['date', 'store_nbr', 'family'], how='left', suffixes=('', '_unpivoted'))
        output = output.drop(['date', 'store_nbr', 'family','onpromotion'], axis=1)
        output.to_csv('submission.csv',index=False)


